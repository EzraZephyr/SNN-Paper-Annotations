
## Spiking PointNet: Spiking Neural Networks for Point Clouds

[论文链接](https://arxiv.org/pdf/2310.06232v1)

将SNN应用于PointNet中 并且提出了静态数据的训练少学习多框架 和膜电位扰动方法

3.1 PointNet是一种用于处理3D点云的网络 并且可以解决其无序性和旋转不变性 参考公式1 给定一组点云数据{x1, x2, ..., xn} 将其通过h 也就是MLP之后 进行最大池化g 以适应其无序性 关于旋转不变性 引入空间变换网络 使其能够处理旋转的点云数据

3.2 使用基本的LIF神经元 参考公式2 其中-(u-urest)项代表膜电位会随时间泄露回静息电位 R为电阻来影响输入电流 当膜电位大于阈值时发放一个脉冲 然后重置膜电位为静息电位u=urest

为了在机器学习框架中训练SNN 公式3展示了一种显示迭代的LIF模型 其中输入电流I为第一式最后两项 分别是上一层神经元j发放的脉冲进行加权求和 和一个偏置b λ为1-(1/τm) 为控制膜电位衰减的速度 通常为0.2 0.25 H为一个阶跃函数控制发放脉冲

ANN和SNN的主要区别就在于非线性计算神经元 将PointNet中的ReLU替换为LIF 就可以将PointNet转换为Spiking PointNet

3.3 然后 因为将ReLU替换为了LIF神经元模型 所以在反向传播的时候会出现一个梯度不可导的问题 首先 权重的梯度参考公式4 可以发现s/u是不可微的 几乎在除阈值外的所有位置都为0 因此需要一个代理梯度 作者这里使用了tanh代理函数 参考公式5 如果将k设置为一个较大的值 可以获得更精确的梯度 因为更接近于H 但是也会导致梯度容易爆炸 而较小的值 则会导致梯度更新平滑 获得的梯度不准确 误差会逐层累积 所以直接训练一个性能良好的时间步大的SNN是非常困难的 这种问题在例如Sigmoid代理函数也会出现

3.4 训练少学习多的框架 参考图4 作者在这里首先将上文代理梯度中的k设置为0.5 5和20 可以发现当k=20时 梯度爆炸和消失非常严重 0.5时 梯度非常平缓 误差很大 当k等于5的时候 在单一时间步下 效果很好 但是如果这个时间步增加到了4 那么梯度的误差问题也会变得很严重 然后表1也表明了 有的时候4个时间步反而比1个时间步表现更差 所以作者这里用一个单一的时间步训练Spiking PointNet 然后在推理的时候使用多个时间步 这样就可以避免梯度爆炸和因为点云多维导致的消耗问题

3.5 膜电位扰动 这里作者验证了 尽管静态的点云数据是没有时序的 但是SNN的多时间提取数据的时空特性也可以应用于静态数据 如果一个神经元没有发放脉冲 那他传递到下一个时刻的膜电位可以被认为一种扰动 这种扰动给不同的时间步提供了不同的初始化 每个时间步的Spiking PointNet可以被视为不同的模型 可以通过平均的方式 相当于集成学习 获得更准确的结果

experiment省略
