
## Addressing the speed-accuracy simulation trade-off for adaptive spiking neurons

[论文链接](https://openreview.net/pdf?id=Ht79ZTVMsn)

改进了ALIF模型 利用ARP(绝对不应期)的特性将他们封装成了块 这样时间复杂度可以降TR(ARP时间)倍

首先介绍了一下标准的的ALIF模型

公式1为发放脉冲 如果t时刻的膜电位超过了动态阈值θ则条件为真 发放脉冲1

公式2为膜电位更新 分别为上一时刻的膜电位和当前时刻的膜电位 用一个可学习的因子β进行控制 如果上一步发放率脉冲 则当前时间步膜电位会直接被屏蔽

公式3为输入的电流 b为固定偏置 分别为前馈电流和循环电流 前馈电流来自前一层的神经元的脉冲 通过加权 加上本层其他神经元的脉冲 同样加权 D为循环传输的延迟 作者这里假设D为固定长度且与ARP相等 TR = D 然后这里如果D不是固定的 只要D>=TR 都是适用的

公式4为ARP的实现 其中C为距离上一次脉冲的时间步数 只有当其>=ARP的长度时 才允许输入电流进入神经元 否则将会被置为0

公式5为动态阈值 基本阈值为θ=1 参考第一式 后面加上一个适应项da d为适应标量 这个适应变量a由一个衰减因子p (0<=p<=1)控制的前一项变量a和前一个时间步是否发放脉冲来控制 若前一个时间步发放了脉冲 则a会增加1 导致阈值增加 反之 a会逐渐衰减 最后为0 导致θ标为基线值1

然后在生物神经元中 ARP通常为1-2ms 在计算神经科学中DT通常为0.1 可以捕捉更精确的时序 在机器学习中常用1 加速计算 但是会牺牲精度

然后在训练部分 脉冲不可导 所以使用代理梯度 比如说Sigmoid来近似 然后膜电位的衰减因子和阈值都可以被训练 之前工作已经证明可以实现并提高精度

3.1
作者在这里提出了一种新的ALIF方法 理论上可以将复杂度O(T)降到O(T/TR) 首先因为正常的SNN是一个时序性的 每一时刻的膜电位都需要依赖上一时刻 这样就导致复杂度一定是 O(T) 但是利用ARP特性 即每个ARP模拟长度只能发放一次脉冲 那么就可以将整个时序网络分成多个ARP块 参考图2b 在每个块里不考虑重置膜电位的影响 并且通过卷积操作一次性计算整个块 参考公式6 这样会导致神经元产生多个错误脉冲 参考公式7 然后 通过ϕ(具体公式看原文命题2)将这个时间块内的脉冲转换为一个潜在的时序z 只保留第一个发放的脉冲 并将这个块内其他位置的值全部设为0 参考公式8 9 这样在每个块内的复杂度就都变成了O(1) (但是块和块之间依旧是正常的时序依赖关系)

3.2 在标准的ALIF的输入电流 公式3和公式4 被修改为命题3中的公式 其中偏置b不变 前馈电流来自每个ARP块的n+1的突触前神经元的脉冲 然后循环电流来自第n个块的突触后神经元的脉冲 其中因为D=ARP的时间TR 所以n和n+1正好差了一个D延迟 所以这个D已经被时间差隐式实现了 这里使用一个潜在时序zi,n[t]衍生的掩码 来确保在发放脉冲后的TR个时间步内的输入电流为0 模拟ARP

每个块内的膜电位演变 参考命题4 每个块的初始膜电位 如果上一个块没有发放脉冲 则继承上一个块的最后时刻的膜电位Vin[TR] 如果发放了脉冲则会被直接重置为0 脉冲后的TR个时间步内处于不应期

阈值的演变 参考命题5 其n+1块的阈值基于初始适应参数ai,n+1[0] 随着时间t衰减 如果上一个块没有脉冲 则继承上一个块的最后一个时间步的值 如果有脉冲则计算为..(看原文) 其中m为脉冲后剩余的时间步 as为一个适应值

3.3 参考表1 虽然复杂度比标准的增加了 但是时序操作下降了 假设两种方法的时序步骤执行时间相等 且非时序操作可并行化 可以获得理论的加速比TR 即ARP长度

experiments省略 