
## MSS-DepthNet: Depth Prediction with Multi-Step Spiking Neural Network

[论文链接](https://arxiv.org/abs/2211.12156)

提出了一种新的网络结构MSS-DepthNet 用于事件相机的深度预测任务

A介绍了使用的数据集MVSEC 用里面的indoorflying序列 关于无人机的 可以提供双目视觉
这里提出的一种输入方法是基于SBT(累积脉冲的方法)进行改进的

每个像素处以50毫秒的时间窗口累计脉冲 通过实验证明这个设置可以最大化信息利用率 参考图2 一个5个时间步的模拟 将异步事件流从(x,y,t,p)转为[T,C,H,W] 这个通道C 双目是4 单目是2

B关于神经元 使用最基础的IF神经元 参考公式1和图3

C网络结构这里的基本架构用的是经典U-Net架构 其中解码器用最近邻插值而不是线性插值 因为线性插值容易引入浮点数 不适合SNN处理 然后在此基础上添加了一个TCSA注意力块

这跟注意力块由三个子模块组成 分别是时间 通道和空间 每个模块都是即插即用 主要放在U-Net的编码器下采样之前 因为这种情况下是最容易丢失信息的部分 和解码器上采样之后 这个时候因为恢复分辨率 会引入噪声

时间注意力模块 输入形状为[T,C,H,W] 会分为两个分支 每个分支由一个一维池化层和一个MLP组成 得到一个1x1xT的注意力图 然后对其分别进行平均池化和最大池化 得到这个时间步相对于总时间步的 然后与原始输入进行逐元素相乘 参考公式2 得到UTA

通道注意力模块 输入形状为[C,H,W] 然后作者讲

和时间注意力的操作很像 所以参考公式2的注意力公式 和公式3的加权 他们的区别是一个沿着时间维度 较大粒度 一个沿着通道维度 较细粒度

空间注意力模块 使用通道注意力模块的输出作为输入 参考公式4 这里的方法和上面差不多 聚焦的是HW了 所以可以理解为是最细粒度的 这三个模块可以参考图5

残差块使用的是MS-ResNet 去除了BN层 并且在最后添加了CSA注意力块 参考图6c

损失 首先真实深度和预测深度的差异为Rk = D^k - Dk 第一个损失函数使用的是尺度不变和位移不变的损失函数 参考公式5 第一项为局部准确性 第二项为全局 第二个损失函数为正则化损失 公式6 使用L1范数 来确保误差空间平滑 然后将两个损失加起来 公式7就是总损失

训练细节看原文 experiments省略