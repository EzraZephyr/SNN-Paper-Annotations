
## Exploring Loss Functions for Time-based Training Strategy in Spiking Neural Networks

[论文链接](https://openreview.net/pdf?id=8IvW2k5VeA)

[附录链接](https://proceedings.neurips.cc/paper_files/paper/2023/file/cde874a797a8300da693d5e412b7fdc0-Supplemental-Conference.pdf

速率编码的损失函数可以通过适当的转换应用于时间编码的反向传播序列中

3
用的模型是脉冲响应模型SRM 参考公式1 其中括号内的为积分范围 从神经元i上次脉冲时间到当前时间 只记录这一段时间内的 其中括号内累积了这一段时间内上一层的神经元发放的脉冲 sj(n-1)(τ)为上一层输入脉冲 τ为发送脉冲的时间 加权 乘上一个脉冲响应核 以计算上一层发放脉冲的时间和现在时间的差距 差距越大贡献越小 公式2为发放脉冲的计算 当膜电位大于阈值时 发射脉冲

关于反向传播 参考公式3 对于第n层神经元i和第n-1层神经元j之间的突触权重 然后对于脉冲时间的梯度 参考公式4 然后因为膜电位在发放脉冲时刻tk是不连续的 会在发放脉冲时重置 所以不可导 所以t/u项需要用一个近似进行替换 参考公式5 如果膜电位增加 脉冲时间提前 然后这个公式5已经被证明梯度在各层守恒 不会出现消失或者爆炸 公式6

4.1 将基于速率的损失梯度转换为基于时间的训练梯度 首先 基于速率的损失梯度是L/s 而时间的是L/t(s) 所以这里用s来作为一个字中间变量来传递 参考公式7 但是这个s/t(s)其实是一个自定义的 所以需要对其添加限制 首先 梯度不应该从一个脉冲传播到另一个脉冲时间 所以当i=i' t=t'时梯度才不为0 其次因为这个是脉冲不连续值对一个发放时刻 所以不可导 会存在无穷大 所以使用一个Dirac Delta函数将顺势脉冲的无穷大转为单位值1 参考公式8

然后如果速率的损失目标是增加脉冲的数量 而增加脉冲的数量会导致发放时间提前 tk减小 那么当L/∫si(tk)大于0时 应该让L/tk减少 但是如果∫si(tk)/tk(si)始终为正值1 那么将不符合预期 所以允许为-1 以符合正确计算

4.2 在4.1中的证明 可以让基于速率的损失通过链式法则转为基于时间的损失 所以作者提出 基于速率的损失可以找到一个等价的基于时间的损失 给出了定理4.1 因为速率的损失本身不涉及脉冲的时间 只关心总数 所以作者构造了一个新的损失让其可以用时间定义 可以使得他们的导数相同 也可以用时间来训练 具体推导查看附录

计数损失 首先参考公式9 λ为一个缩放常数 si(t)dt为第i个神经元在总时间内的脉冲总数 和目标脉冲数量target进行计算 C为类别数量 然后根据上面计算的Dirac Delta函数损失 当所有si(tk)/tk(si) = 1时 得到公式10 具体步骤看附录 然后这里可以看出 当一发射的脉冲数量超过目标时 鼓励更早发射 反之鼓励更晚发射 这一点和预期相反 所以直接把1改为-1 证明上文

脉冲序列差异的损失 测量了两个经过滤波的脉冲序列之间的高度差异 参考公式11 首先starget是输出神经元的目标序列 sitarget是神经元i的目标脉冲序列 用一个卷积核平滑脉冲序列 跟时间有关 因为他需要控制发放脉冲的曲线 而定理4.1是能把完全不用时间的损失改成会用到时间的损失 所以用不了 然后看图2ab 在这种情况下 应该期望的是脉冲时间更早 像左移动 而实际的优化确实上下移动 这与目标的调整冲突 而cd就没有 因为在这些场景下 当脉冲序列密集到可以覆盖所有时间范围 包括目标输出为空时 上下调整可以进行优化 所以 将∫si(tk)/tk(si) = -1让其更早的对应起来 证明上文

4.3 平衡正负向梯度 如果正负向梯度不平衡 那么梯度总和会偏向一方 导致训练不稳定 当∫si(tk)/tk(si) = -1 且标签神经元的目标脉冲较大时 参考公式12 梯度将会总是正向

4.4 基于刚才的分析 作者提出了一个增强计数损失函数 看原文 将其中公式12的二次项m转变为一个线性m 新的计数损失梯度公式为13 当x=0没有脉冲时 损失应该为0 设定边界 公式14

4.5 在之前的工作中 使用W γ β分别是原始权重 缩放因子 和平移因子 来进行权重标准化 稳定训练 参考公式15 但是在这里的网络中不适用 因为基于时间的训练 权重w会直接影响梯度 参考公式16 17 而权重又是通过公式15计算的 所以γ的变化会直接改变w 影响训练的稳定 但是 阈值在上述的反向传播中并没有出现 所以学习阈值可能会稳定训练过程 在公式1 2中 可以发现将权重和阈值按相同因子放大不会改变输出脉冲序列 所以固定γ为γ0 在进行参数更新时 看原文公式 更新规则可以被描述为公式19 20

experiments省略
