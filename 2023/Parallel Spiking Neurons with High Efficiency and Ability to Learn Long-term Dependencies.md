
## Parallel Spiking Neurons with High Efficiency and Ability to Learn Long-term Dependencies

[论文链接](https://arxiv.org/pdf/2304.12760)

提出了一种新的神经元PSN 可以进行并行训练和长期依赖

3.1这里介绍了基本的神经元模型公式 参考公式1到公式3 不同的神经元模型对于f函数是不同的 但是行为一样 都是通过f函数计算中间时刻的膜电位 然后用阶跃函数判断膜电位是否超过了阈值 然后如果超过了阈值则发放脉冲 然后分为软重置和硬重置 软重置就是将膜电位减少一个阈值的量 硬重置就是直接设置为Vreset 这两种重置的在不同情况下被不同选择 代理训练一般用硬重置 而ANN转SNN喜欢用软重置

然后 作者在这里假设了一个条件 假如中间膜电位H[t]在所有的时间步均小于阈值Vth 忽略重置项 这意味着将不会触发重置 H[t]可以直接通过输入X计算 那么H可以直接等于V等于X

假设H[-1] = 0 这个概念对于IF模型 参考公式4 5 没有膜电位衰减所以可以直接写为输入的累加形式

LIF模型稍微复杂一点 参考公式6 7 需要对每一时刻的输入 根据t和i的距离来进行衰减 距离越远影响越小

通过这样的写法 可以让模型计算从串行变成并行 不用依赖前一个时间步 复杂度降到O(log(T))

然后作者提出了两种方法忽略重置 第一种是把阈值Vth设置为正无穷 但是这样会让其永远无法发送脉冲 失去实际意义 第二种是直接移除重置这一概念 即使放电也会持续累积 但是这种方法 从表面上看会引起一个不间断的发放脉冲的问题

3.2
在刚才说移除重置后 可以直接被简化为一个非迭代方程 参考公式8 直接通过加权输入累加得到

对于IF神经元 权重W = Θ(t-i) 即只计算时间步之前 而不会扩展到未来 对于LIF神经元 看原文

依据此 作者提出了PSN 参考公式9 10 其中W是一个TxT的可学习的权重矩阵 X作为输入序列 这样一次性计算了所有时间步的H 然后对H和一个可学习的阈值B进行逐元素比较 生成脉冲01序列 这样就可以保证不会无限发放脉冲 而且可以将所有时间步和中间状态H进行并行计算 能捕捉到整个序列的长期依赖关系

3.3
这种PSN也会导致一个问题 就是他必须等所有的X[t]到齐之后才可以进行计算 这会增加T的延迟 在推理阶段 作者这里提出来了一个掩码机制 公式11 其中M[i][j]参考公式12 这里表明了只让H依赖于最近的k个输入 而不是所有的T 超出k个范围将会被置为0

而在训练阶段 需要让网络看到未来的信息 所以掩码参考公式13 在训练刚开始时 λ为0 即所有元素都为1 这样使H依赖所有时间步的输入 学习全局信息 到网络后期λ逐渐接近于1 开始依赖最近k个输入 使其与推理时的计算方法一致

3.4
然后 刚才说的方法是基于固定的TxT的输入 但是如果T时可变的 那么W和Mk也需要跟着调整 这需要额外的操作 所以作者提出了一种滑动PSN以解决此问题 参考公式14 15 X[t-k+1+i]类似于一种卷积范围 卷积核W的长度为k 在输入序列X上滑动 然后对于j<0 X[j] = 0以处理边界 其中公式14中的W也可以被一种滑动矩阵A代替 参考公式16 这样可以将卷积操作转变为矩阵乘法操作H=AX 速度比卷积快

experiments省略
