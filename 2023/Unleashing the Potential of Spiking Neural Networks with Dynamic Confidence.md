
## Unleashing the Potential of Spiking Neural Networks with Dynamic Confidence

[论文链接](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.pdf)

将置信度的概念添加到SNN中

5 作者方法的目标是通过使用由模型输出确定的置信度指标 为每次推理动态分配计算资源

5.1 在多分类问题中 给定一个输入样本X 标签Y ANN f() 输出为f(X) = (Y^, P^)其中Y^为预测的输出标签 P^∈[0,1]是该预测的置信度 为对预测的自信程度的一种量化 P^越高模型越认为自己的预测是准确的 反之 然后 置信度在一些场景中非常重要 比如医疗和自动驾驶 还可以用来理解神经网络的可解释性 能与其他概率模型交互

校准只能提高置信度的质量 完全校准模型是无法实现的 因为会存在过自信和欠自信的问题 导致置信度和真实的正确率不一致 作者这里采用了一种经典的校准算法 温度缩放

5.2 在经过ANN到SNN的转换之后 ANN f()会变成SNN fs() 而SNN会生成一系列的输出(Yt^, Pt^) 其中t ∈T 按照整成情况来讲 在测试集中 预测精度会随着时间步增加而提高 所以会存在一个当t2>t1时 Yt2^ = Y比Yt1^=Y更有可能发生 同理 Pt2^应该比Pt1^要高

参考图2a 蓝色线为SNN的传统精度延迟响应曲线 橙色线是对正确可能性P(Yt^=Y)的估计 可以看出来这两条线的趋势是相同的 低置信度代表Yt^ = Y的可能性较低 反之会很高 在这期间Y是位置的 但是这种置信度可以对其进行隐式估计 达到某个阈值时提前终止推理输出结果

从图2a也可以发现一个问题 就是橙色的置信度曲线增长的过于迅速 很短的时间内就增长到了近乎100 这种饱和问题会导致置信度没有进一步的改进空间 这种问题是由于SNN的输出格式引起的 例如在一些积分但不发放的神经元中 x会持续增加 导致zt持续增加 公式2 再加上softmax指数运算的特性 导致置信度稍微偏向一个值后 就会迅速增长 没有挽回余地

所以作者引入了一个α 参考公式1来对确保再时间T之前不会过分饱和 并且将最后一个时间步的置信度和ANN输出的置信度对其 关于选择这个α的值 不同的方法可以存在不同的设置 比如说QFFS 可以设置α = 2^b-1 b为量化位精度 作者这里选择直接将α设为T 图2b展示了缩放后的 可以看见软化了很多

5.3 在测试的过程中 通过假定可以访问目标标签Y 并假定置信度Pt^是高度可靠的 是最完美估计 设定一个置信度阈值 当某个时间步超越了这个阈值 则终止输出结果 这在CIFAR10内 仅1.28个时间步达到了95.1%的精度 其余测试结果看原文

这个阈值通过Pareto前沿最优解来找 将阈值以0.1离散化为11个解 查看图3 绘制了这11个th 可以看出 与基线解相比能提供最低延迟且不损失精度 0.6是最优阈值

experiments省略